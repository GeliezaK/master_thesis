{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89a6c9bb",
   "metadata": {},
   "source": [
    "# Export Sentinel-2 data for surface solar irradiance model\n",
    "\n",
    "This Jupyter notebook implements an export pipeline for Sentinel-2 cloud mask images using Google Earth Engine. All subsequent modeling steps are performed in Python, outside Google Earth Engine, using the exported files.\n",
    "\n",
    "The notebook is designed to be reproducible and can be executed by any user with a Google account and a\n",
    "Google Cloud project linked to Earth Engine.\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "To run this notebook, you need:\n",
    "\n",
    "1. **A Google account**\n",
    "2. **Access to Google Earth Engine**\n",
    "3. **A Google Cloud project linked to Earth Engine**\n",
    "4. **A local Python environment with the required packages installed**\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Step 1 – Create a Google Earth Engine Account\n",
    "\n",
    "1. Go to the Earth Engine signup page:  \n",
    "   https://earthengine.google.com/\n",
    "\n",
    "2. Click **“Sign up”** and log in with your Google account.\n",
    "\n",
    "3. Request access to **Earth Engine for research / non-commercial use** and wait for approval.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 2 – Create a Google Cloud Project\n",
    "\n",
    "Earth Engine requires a Google Cloud project for authentication and billing association\n",
    "(no charges are incurred for typical research use).\n",
    "\n",
    "1. Go to the Google Cloud Console:  \n",
    "   https://console.cloud.google.com/\n",
    "\n",
    "2. Create a **new project** and choose a project name.\n",
    "\n",
    "3. Note the **Project ID** - this will be required for authentication.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 3 – Link the Cloud Project to Earth Engine\n",
    "\n",
    "1. Open the Earth Engine Code Editor:  \n",
    "   https://code.earthengine.google.com/\n",
    "\n",
    "2. Click the ⚙️ **Settings** icon (top right).\n",
    "\n",
    "3. Under **Cloud Projects**, select or add your newly created Google Cloud project.\n",
    "\n",
    "4. Save the settings.\n",
    "\n",
    "This links Earth Engine to your Cloud project and enables API access from Python.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 4 – Set Up the Local Python Environment\n",
    "\n",
    "Install the required Python packages (example using `pip`):\n",
    "\n",
    "```bash\n",
    "pip install earthengine-api geemap numpy pandas xarray rasterio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ab02271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ee\n",
    "import geemap\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68a33d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Authorization and initialization of the GEE\n",
    "# OBS: You must create our own project on Google\n",
    "# Authenticate Earth Engine\n",
    "ee.Authenticate()\n",
    "#\n",
    "# Initialize Earth Engine\n",
    "my_project_name = 'sample-project-452812' # use here the name of your own project on Google\n",
    "ee.Initialize(project=my_project_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f6113be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'north': 60.50219617276416, 'south': 60.27780382723584, 'west': 5.10273148294384, 'east': 5.55726851705616}\n",
      "{'north': 60.50219617276416, 'south': 59.3802344451226, 'west': 4.739101855653983, 'east': 5.920898144346017}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a961132749b40c48d93b6ee3e295d3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[60.39, 5.33], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=SearchDataGUI…"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -------------------------------------------\n",
    "# Definition of study area \n",
    "# -------------------------------------------\n",
    "\n",
    "# Convert degree to radian\n",
    "def deg2rad(deg):\n",
    "    return deg * math.pi / 180\n",
    "\n",
    "# Define the center of the bounding box (Bergen, Norway)\n",
    "CENTER_LAT = 60.39\n",
    "CENTER_LON = 5.33\n",
    "\n",
    "# Approximate degree adjustments for 100km x 100km box\n",
    "DEG_LAT_TO_KM = 111.412  # 1 degree latitude at 60° converted to km (https://en.wikipedia.org/wiki/Latitude)\n",
    "DEG_LON_TO_KM = 111.317 * math.cos(deg2rad(CENTER_LAT))  # 1 degree longitude converted to km\n",
    "LAT_OFFSET = 12.5 / DEG_LAT_TO_KM  # north/south\n",
    "LON_OFFSET = 12.5 / DEG_LON_TO_KM  # east/west \n",
    "\n",
    "# Define the bounding box\n",
    "BBOX = {\n",
    "    \"north\": CENTER_LAT + LAT_OFFSET,\n",
    "    \"south\": CENTER_LAT - LAT_OFFSET,\n",
    "    \"west\": CENTER_LON - LON_OFFSET,\n",
    "    \"east\": CENTER_LON + LON_OFFSET\n",
    "}\n",
    "\n",
    "print(BBOX)\n",
    "\n",
    "# Define large bounding box for cloud mask retrieval \n",
    "# These values are defined specificly for Bergen after analyzing the satellite and solar angles \n",
    "# over Bergen at 11 UTC (Sentinel-2 overpass time) and need to be adapted for other regions of the world. \n",
    "LSOUTH_OFFSET = 100 / DEG_LAT_TO_KM  # add another 100 km south\n",
    "LWEST_OFFSET =  20 / DEG_LON_TO_KM  # add 20 km west \n",
    "LEAST_OFFSET = 20 / DEG_LON_TO_KM  # add 20 km east \n",
    "\n",
    "# Define the bounding box\n",
    "LBOX = {\n",
    "    \"north\": CENTER_LAT + LAT_OFFSET,\n",
    "    \"south\": BBOX[\"south\"] - LSOUTH_OFFSET,\n",
    "    \"west\": BBOX[\"west\"] - LWEST_OFFSET,\n",
    "    \"east\": BBOX[\"east\"] + LEAST_OFFSET\n",
    "}\n",
    "\n",
    "print(LBOX)\n",
    "\n",
    "# Geometry Rectangle small and large region of interest (roi)\n",
    "bergen_small_roi = ee.Geometry.Rectangle([BBOX[\"west\"], BBOX[\"south\"], BBOX[\"east\"], BBOX[\"north\"]])\n",
    "bergen_large_roi = ee.Geometry.Rectangle([LBOX[\"west\"], LBOX[\"south\"], LBOX[\"east\"], LBOX[\"north\"]])\n",
    "\n",
    "Map = geemap.Map(center=[CENTER_LAT, CENTER_LON], zoom=10)\n",
    "\n",
    "# Add the geometry to the map\n",
    "Map.addLayer(bergen_small_roi, {\"color\": \"red\"}, \"Bergen ROI\")\n",
    "Map.addLayer(bergen_large_roi, {\"color\": \"blue\"}, \"Bergen large ROI\")\n",
    "\n",
    "# Display the weather stations\n",
    "stations = {\n",
    "    \"Flesland Bergen\": (60.292792, 5.222689),\n",
    "    \"Florida\": (60.3833, 5.3333)\n",
    "}\n",
    "\n",
    "for name, (lat, lon) in stations.items():\n",
    "    point = ee.Geometry.Point([lon, lat])\n",
    "    Map.addLayer(point, {\"color\": \"red\"}, name)\n",
    "    \n",
    "# Add elevation map from Hoydedata National Elevation Project 1m\n",
    "dsm = ee.Image(\"projects/sample-project-452812/assets/bergen_dsm_1m_zip\").clip(bergen_small_roi)\n",
    "\n",
    "elevation_vis = {\n",
    "    'min': 0,\n",
    "    'max': 800,\n",
    "    'palette': ['blue', \"green\", 'brown', 'white']\n",
    "}\n",
    "\n",
    "Map.addLayer(dsm, elevation_vis, 'Elevation (DSM 1m)')\n",
    "\n",
    "# Display the map\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd03a93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both exports started. Check the Earth Engine Tasks tab or Google Drive when finished.\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------\n",
    "# Preprocess DSM \n",
    "# ------------------------------------\n",
    "\n",
    "# Load original 1 m DSM and clip to ROI\n",
    "# DSM originally downloaded from https://hoydedata.no/LaserInnsyn2/ and uploaded to Earth Engine as asset\n",
    "dsm = ee.Image(\"projects/sample-project-452812/assets/bergen_dsm_1m_zip\").clip(bergen_small_roi)\n",
    "\n",
    "# Reproject DSM to EPSG:4326\n",
    "dsm_1m = dsm.reproject(crs=\"EPSG:4326\", scale=1)\n",
    "\n",
    "# Resample to 10m and reproject\n",
    "dsm_10m = dsm.reproject(crs=\"EPSG:4326\", scale=10)\n",
    "dsm_10m_mean = (dsm\n",
    "           .reduceResolution(reducer=ee.Reducer.mean(), maxPixels=1024)\n",
    "           .reproject(crs=\"EPSG:4326\", scale=10))\n",
    "\n",
    "# Export 1m DSM to Google Drive\n",
    "task1 = ee.batch.Export.image.toDrive(\n",
    "    image=dsm_1m,\n",
    "    description=\"DSM_Bergen_1m_WGS84\",\n",
    "    folder=\"EarthEngineExports\",\n",
    "    fileNamePrefix=\"bergen_dsm_1m_epsg4326\",\n",
    "    scale=1,\n",
    "    region=bergen_small_roi,\n",
    "    crs=\"EPSG:4326\",\n",
    "    maxPixels=1e13\n",
    ")\n",
    "\n",
    "# Export 10m DSM to Google Drive\n",
    "task2 = ee.batch.Export.image.toDrive(\n",
    "    image=dsm_10m,\n",
    "    description=\"DSM_Bergen_10m_WGS84_mean\",\n",
    "    folder=\"EarthEngineExports\",\n",
    "    fileNamePrefix=\"bergen_dsm_10m_epsg4326_reducer_mean\",\n",
    "    scale=10,\n",
    "    region=bergen_small_roi,\n",
    "    crs=\"EPSG:4326\",\n",
    "    maxPixels=1e13\n",
    ")\n",
    "\n",
    "# Start both tasks\n",
    "task1.start()\n",
    "task2.start()\n",
    "\n",
    "print(\"Both exports started. Check the Earth Engine Tasks tab or Google Drive when finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "59692aaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "# Helper functions for preprocessing and exporting Sentinel-2 images \n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "# Binary mask for cloud mask\n",
    "CLD_PRB_THRESH = 40 \n",
    "\n",
    "# Turn int data to binary using recommended threshold, \n",
    "# from s2cloudless paper: https://www.sciencedirect.com/science/article/pii/S0034425722001043?via%3Dihub \n",
    "def add_cloud_mask(image):\n",
    "    cloud_mask = image.select('probability').gt(CLD_PRB_THRESH).rename('cloud_mask')\n",
    "    # drop band probability immediately for performance reasons\n",
    "    return image.addBands(cloud_mask).select(['cloud_mask'])\n",
    "\n",
    "# Count how many pixels are actually in bergen_roi\n",
    "def has_valid_pixels(img, roi):\n",
    "    # Reduce over ROI, count non-masked pixels\n",
    "    count = img.reduceRegion(\n",
    "        reducer=ee.Reducer.count(),\n",
    "        geometry=roi,\n",
    "        scale=img.projection().nominalScale(),\n",
    "        maxPixels=1e9\n",
    "    ).values().get(0)  # get the first band's count\n",
    "\n",
    "    # Set property to image\n",
    "    return img.set('validPixelCount', count)\n",
    "\n",
    "def add_date(img):\n",
    "    # Add YYYY-MM-dd as property\n",
    "    return img.set('date', img.date().format('YYYY-MM-dd'))\n",
    "\n",
    "# Combine multiple images into one per day (to cover whole Bergen area in one image)\n",
    "def daily_mosaic(ic):\n",
    "    # Get unique dates\n",
    "    dates = ic.aggregate_array('date').distinct()\n",
    "    \n",
    "    def make_mosaic(d):\n",
    "        d = ee.String(d)\n",
    "        daily_ic = ic.filter(ee.Filter.eq('date', d))\n",
    "        \n",
    "        # Get list of acquisition times\n",
    "        times = daily_ic.aggregate_array('system:time_start')\n",
    "        min_time = ee.Number(times.reduce(ee.Reducer.min()))\n",
    "        max_time = ee.Number(times.reduce(ee.Reducer.max()))\n",
    "        time_range = max_time.subtract(min_time)\n",
    "        \n",
    "        mosaic = daily_ic.mosaic()\n",
    "        \n",
    "        return (mosaic\n",
    "                .set('date', d)\n",
    "                .set('system:time_start', min_time)   # earliest time\n",
    "                .set('start_time_range', time_range)) # span of times\n",
    "    \n",
    "    return ee.ImageCollection(dates.map(make_mosaic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a44f7724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch: 2015-06-01 to 2015-12-01\n",
      "Export started: S2_viewing_angles_large_2015-06\n",
      "Processing batch: 2015-12-01 to 2016-06-01\n",
      "Export started: S2_viewing_angles_large_2015-12\n",
      "Processing batch: 2016-06-01 to 2016-12-01\n",
      "Export started: S2_viewing_angles_large_2016-06\n",
      "Processing batch: 2016-12-01 to 2017-06-01\n",
      "Export started: S2_viewing_angles_large_2016-12\n",
      "Processing batch: 2017-06-01 to 2017-12-01\n",
      "Export started: S2_viewing_angles_large_2017-06\n",
      "Processing batch: 2017-12-01 to 2018-06-01\n",
      "Export started: S2_viewing_angles_large_2017-12\n",
      "Processing batch: 2018-06-01 to 2018-12-01\n",
      "Export started: S2_viewing_angles_large_2018-06\n",
      "Processing batch: 2018-12-01 to 2019-06-01\n",
      "Export started: S2_viewing_angles_large_2018-12\n",
      "Processing batch: 2019-06-01 to 2019-12-01\n",
      "Export started: S2_viewing_angles_large_2019-06\n",
      "Processing batch: 2019-12-01 to 2020-06-01\n",
      "Export started: S2_viewing_angles_large_2019-12\n",
      "Processing batch: 2020-06-01 to 2020-12-01\n",
      "Export started: S2_viewing_angles_large_2020-06\n",
      "Processing batch: 2020-12-01 to 2021-06-01\n",
      "Export started: S2_viewing_angles_large_2020-12\n",
      "Processing batch: 2021-06-01 to 2021-12-01\n",
      "Export started: S2_viewing_angles_large_2021-06\n",
      "Processing batch: 2021-12-01 to 2022-06-01\n",
      "Export started: S2_viewing_angles_large_2021-12\n",
      "Processing batch: 2022-06-01 to 2022-12-01\n",
      "Export started: S2_viewing_angles_large_2022-06\n",
      "Processing batch: 2022-12-01 to 2023-06-01\n",
      "Export started: S2_viewing_angles_large_2022-12\n",
      "Processing batch: 2023-06-01 to 2023-12-01\n",
      "Export started: S2_viewing_angles_large_2023-06\n",
      "Processing batch: 2023-12-01 to 2024-06-01\n",
      "Export started: S2_viewing_angles_large_2023-12\n",
      "Processing batch: 2024-06-01 to 2024-12-01\n",
      "Export started: S2_viewing_angles_large_2024-06\n",
      "Processing batch: 2024-12-01 to 2025-06-01\n",
      "Export started: S2_viewing_angles_large_2024-12\n",
      "Processing batch: 2025-06-01 to 2025-08-31\n",
      "Export started: S2_viewing_angles_large_2025-06\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# Export pipeline for Sentinel 2 viewing angles\n",
    "# =========================================================\n",
    "\n",
    "# -----------------------------\n",
    "# Parameters\n",
    "# -----------------------------\n",
    "start_date_total = ee.Date(\"2015-06-01\")\n",
    "end_date_total   = ee.Date(\"2025-08-31\")\n",
    "batch_months = 6   # adjust for your case\n",
    "drive_folder = \"S2_viewing_angles\"\n",
    "\n",
    "# -----------------------------\n",
    "# Properties of interest\n",
    "# -----------------------------\n",
    "# Bands used in s2cloudless algorithm\n",
    "bands = ['B1','B2','B3','B4','B5','B6','B7','B8','B8A','B9','B10','B11','B12']\n",
    "azimuth_keys = [f'MEAN_INCIDENCE_AZIMUTH_ANGLE_{b}' for b in bands]\n",
    "zenith_keys  = [f'MEAN_INCIDENCE_ZENITH_ANGLE_{b}' for b in bands]\n",
    "all_keys = azimuth_keys + zenith_keys\n",
    "all_keys = all_keys + ['system:time_start', 'DATASTRIP_ID', 'DATATAKE_IDENTIFIER', \n",
    "                'GRANULE_ID', 'MGRS_TILE', 'PRODUCT_ID', 'SENSING_ORBIT_DIRECTION', \n",
    "                'SENSING_ORBIT_NUMBER', 'SPACECRAFT_NAME']  # include timestamp and granule identifiers\n",
    "\n",
    "# Convert image → feature (table of properties)\n",
    "def img_to_feature(img):\n",
    "    props = img.toDictionary(all_keys)\n",
    "    return ee.Feature(None, props)\n",
    "\n",
    "# Export FeatureCollection to Drive\n",
    "def export_table(fc, description):\n",
    "    task = ee.batch.Export.table.toDrive(\n",
    "        collection=fc,\n",
    "        description=description,\n",
    "        folder=drive_folder,\n",
    "        fileFormat='CSV'\n",
    "    )\n",
    "    task.start()\n",
    "    print(f\"Export started: {description}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Batch processing and export\n",
    "# -----------------------------\n",
    "current_start = start_date_total\n",
    "\n",
    "while current_start.millis().getInfo() < end_date_total.millis().getInfo():\n",
    "    # Define batch end date\n",
    "    current_end = current_start.advance(batch_months, 'month')\n",
    "    if current_end.millis().getInfo() > end_date_total.millis().getInfo():\n",
    "        current_end = end_date_total\n",
    "\n",
    "    print(f\"Processing batch: {current_start.format('YYYY-MM-dd').getInfo()} \"\n",
    "          f\"to {current_end.format('YYYY-MM-dd').getInfo()}\")\n",
    "\n",
    "    # Load S2 harmonized collection for large ROI\n",
    "    s2_harm_large_roi = (ee.ImageCollection(\"COPERNICUS/S2_HARMONIZED\") \\\n",
    "        .filterDate(current_start, current_end) \\\n",
    "        .filterBounds(bergen_large_roi)) \\\n",
    "        .select(\"B1\") # select only one band for memory efficiency\n",
    "\n",
    "    # Convert to feature collection\n",
    "    fc = s2_harm_large_roi.map(img_to_feature)\n",
    "\n",
    "    # Export batch table\n",
    "    export_table(fc, f\"S2_viewing_angles_large_{current_start.format('YYYY-MM').getInfo()}\")\n",
    "\n",
    "    # Move to next batch\n",
    "    current_start = current_end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ea6b8090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch: 2015-06-01 to 2015-09-01\n",
      "Export started: S2_cloud_cover_small_thresh_40_2015-06\n",
      "Export started: S2_cloud_cover_large_thresh_40_2015-06\n",
      "Processing batch: 2015-09-01 to 2015-12-01\n",
      "Export started: S2_cloud_cover_small_thresh_40_2015-09\n",
      "Export started: S2_cloud_cover_large_thresh_40_2015-09\n",
      "Processing batch: 2015-12-01 to 2016-03-01\n",
      "Export started: S2_cloud_cover_small_thresh_40_2015-12\n",
      "Export started: S2_cloud_cover_large_thresh_40_2015-12\n",
      "Processing batch: 2016-03-01 to 2016-06-01\n",
      "Export started: S2_cloud_cover_small_thresh_40_2016-03\n",
      "Export started: S2_cloud_cover_large_thresh_40_2016-03\n",
      "Processing batch: 2016-06-01 to 2016-09-01\n",
      "Export started: S2_cloud_cover_small_thresh_40_2016-06\n",
      "Export started: S2_cloud_cover_large_thresh_40_2016-06\n",
      "Processing batch: 2016-09-01 to 2016-12-01\n",
      "Export started: S2_cloud_cover_small_thresh_40_2016-09\n",
      "Export started: S2_cloud_cover_large_thresh_40_2016-09\n",
      "Processing batch: 2016-12-01 to 2017-03-01\n",
      "Export started: S2_cloud_cover_small_thresh_40_2016-12\n",
      "Export started: S2_cloud_cover_large_thresh_40_2016-12\n",
      "Processing batch: 2017-03-01 to 2017-06-01\n",
      "Export started: S2_cloud_cover_small_thresh_40_2017-03\n",
      "Export started: S2_cloud_cover_large_thresh_40_2017-03\n",
      "Processing batch: 2017-06-01 to 2017-09-01\n",
      "Export started: S2_cloud_cover_small_thresh_40_2017-06\n",
      "Export started: S2_cloud_cover_large_thresh_40_2017-06\n",
      "Processing batch: 2017-09-01 to 2017-12-01\n",
      "Export started: S2_cloud_cover_small_thresh_40_2017-09\n",
      "Export started: S2_cloud_cover_large_thresh_40_2017-09\n",
      "Processing batch: 2017-12-01 to 2018-03-01\n",
      "Export started: S2_cloud_cover_small_thresh_40_2017-12\n",
      "Export started: S2_cloud_cover_large_thresh_40_2017-12\n",
      "Processing batch: 2018-03-01 to 2018-06-01\n",
      "Export started: S2_cloud_cover_small_thresh_40_2018-03\n",
      "Export started: S2_cloud_cover_large_thresh_40_2018-03\n",
      "Processing batch: 2018-06-01 to 2018-09-01\n",
      "Export started: S2_cloud_cover_small_thresh_40_2018-06\n",
      "Export started: S2_cloud_cover_large_thresh_40_2018-06\n",
      "Processing batch: 2018-09-01 to 2018-12-01\n",
      "Export started: S2_cloud_cover_small_thresh_40_2018-09\n",
      "Export started: S2_cloud_cover_large_thresh_40_2018-09\n",
      "Processing batch: 2018-12-01 to 2019-03-01\n",
      "Export started: S2_cloud_cover_small_thresh_40_2018-12\n",
      "Export started: S2_cloud_cover_large_thresh_40_2018-12\n",
      "Processing batch: 2019-03-01 to 2019-06-01\n",
      "Export started: S2_cloud_cover_small_thresh_40_2019-03\n",
      "Export started: S2_cloud_cover_large_thresh_40_2019-03\n",
      "Processing batch: 2019-06-01 to 2019-09-01\n",
      "Export started: S2_cloud_cover_small_thresh_40_2019-06\n",
      "Export started: S2_cloud_cover_large_thresh_40_2019-06\n",
      "Processing batch: 2019-09-01 to 2019-12-01\n",
      "Export started: S2_cloud_cover_small_thresh_40_2019-09\n",
      "Export started: S2_cloud_cover_large_thresh_40_2019-09\n",
      "Processing batch: 2019-12-01 to 2020-03-01\n",
      "Export started: S2_cloud_cover_small_thresh_40_2019-12\n",
      "Export started: S2_cloud_cover_large_thresh_40_2019-12\n",
      "Processing batch: 2020-03-01 to 2020-06-01\n",
      "Export started: S2_cloud_cover_small_thresh_40_2020-03\n",
      "Export started: S2_cloud_cover_large_thresh_40_2020-03\n",
      "Processing batch: 2020-06-01 to 2020-09-01\n",
      "Export started: S2_cloud_cover_small_thresh_40_2020-06\n",
      "Export started: S2_cloud_cover_large_thresh_40_2020-06\n",
      "Processing batch: 2020-09-01 to 2020-12-01\n",
      "Export started: S2_cloud_cover_small_thresh_40_2020-09\n",
      "Export started: S2_cloud_cover_large_thresh_40_2020-09\n",
      "Processing batch: 2020-12-01 to 2021-03-01\n",
      "Export started: S2_cloud_cover_small_thresh_40_2020-12\n",
      "Export started: S2_cloud_cover_large_thresh_40_2020-12\n",
      "Processing batch: 2021-03-01 to 2021-06-01\n",
      "Export started: S2_cloud_cover_small_thresh_40_2021-03\n",
      "Export started: S2_cloud_cover_large_thresh_40_2021-03\n",
      "Processing batch: 2021-06-01 to 2021-09-01\n",
      "Export started: S2_cloud_cover_small_thresh_40_2021-06\n",
      "Export started: S2_cloud_cover_large_thresh_40_2021-06\n",
      "Processing batch: 2021-09-01 to 2021-12-01\n",
      "Export started: S2_cloud_cover_small_thresh_40_2021-09\n",
      "Export started: S2_cloud_cover_large_thresh_40_2021-09\n",
      "Processing batch: 2021-12-01 to 2022-03-01\n",
      "Export started: S2_cloud_cover_small_thresh_40_2021-12\n",
      "Export started: S2_cloud_cover_large_thresh_40_2021-12\n",
      "Processing batch: 2022-03-01 to 2022-06-01\n",
      "Export started: S2_cloud_cover_small_thresh_40_2022-03\n",
      "Export started: S2_cloud_cover_large_thresh_40_2022-03\n",
      "Processing batch: 2022-06-01 to 2022-09-01\n",
      "Export started: S2_cloud_cover_small_thresh_40_2022-06\n",
      "Export started: S2_cloud_cover_large_thresh_40_2022-06\n",
      "Processing batch: 2022-09-01 to 2022-12-01\n",
      "Export started: S2_cloud_cover_small_thresh_40_2022-09\n",
      "Export started: S2_cloud_cover_large_thresh_40_2022-09\n",
      "Processing batch: 2022-12-01 to 2023-03-01\n",
      "Export started: S2_cloud_cover_small_thresh_40_2022-12\n",
      "Export started: S2_cloud_cover_large_thresh_40_2022-12\n",
      "Processing batch: 2023-03-01 to 2023-06-01\n",
      "Export started: S2_cloud_cover_small_thresh_40_2023-03\n",
      "Export started: S2_cloud_cover_large_thresh_40_2023-03\n",
      "Processing batch: 2023-06-01 to 2023-09-01\n",
      "Export started: S2_cloud_cover_small_thresh_40_2023-06\n",
      "Export started: S2_cloud_cover_large_thresh_40_2023-06\n",
      "Processing batch: 2023-09-01 to 2023-12-01\n",
      "Export started: S2_cloud_cover_small_thresh_40_2023-09\n",
      "Export started: S2_cloud_cover_large_thresh_40_2023-09\n",
      "Processing batch: 2023-12-01 to 2024-03-01\n",
      "Export started: S2_cloud_cover_small_thresh_40_2023-12\n",
      "Export started: S2_cloud_cover_large_thresh_40_2023-12\n",
      "Processing batch: 2024-03-01 to 2024-06-01\n",
      "Export started: S2_cloud_cover_small_thresh_40_2024-03\n",
      "Export started: S2_cloud_cover_large_thresh_40_2024-03\n",
      "Processing batch: 2024-06-01 to 2024-09-01\n",
      "Export started: S2_cloud_cover_small_thresh_40_2024-06\n",
      "Export started: S2_cloud_cover_large_thresh_40_2024-06\n",
      "Processing batch: 2024-09-01 to 2024-12-01\n",
      "Export started: S2_cloud_cover_small_thresh_40_2024-09\n",
      "Export started: S2_cloud_cover_large_thresh_40_2024-09\n",
      "Processing batch: 2024-12-01 to 2025-03-01\n",
      "Export started: S2_cloud_cover_small_thresh_40_2024-12\n",
      "Export started: S2_cloud_cover_large_thresh_40_2024-12\n",
      "Processing batch: 2025-03-01 to 2025-06-01\n",
      "Export started: S2_cloud_cover_small_thresh_40_2025-03\n",
      "Export started: S2_cloud_cover_large_thresh_40_2025-03\n",
      "Processing batch: 2025-06-01 to 2025-08-31\n",
      "Export started: S2_cloud_cover_small_thresh_40_2025-06\n",
      "Export started: S2_cloud_cover_large_thresh_40_2025-06\n"
     ]
    }
   ],
   "source": [
    "# =====================================================================\n",
    "# Export pipeline for cloud cover information large and small roi\n",
    "# =====================================================================\n",
    "\n",
    "# -----------------------------\n",
    "# Parameters\n",
    "# -----------------------------\n",
    "start_date_total = ee.Date(\"2015-06-01\")\n",
    "end_date_total   = ee.Date(\"2025-08-31\")\n",
    "batch_months = 3   # small batch size enables faster processing \n",
    "drive_folder = \"S2_cloud_cover_tables_thresh_40\"\n",
    "\n",
    "# -----------------------------\n",
    "# Helper functions\n",
    "# -----------------------------\n",
    "\n",
    "def add_constant(image): \n",
    "    valid_pixel = image.select('cloud_mask').gte(0).rename('valid_pixel')\n",
    "    return image.addBands(valid_pixel)\n",
    "\n",
    "# Add cloud cover to both large and small roi \n",
    "def add_cloud_cover(img, roi):\n",
    "    # Assume cloud_mask is a binary mask: 1 = cloud, 0 = clear\n",
    "    cloud_mask = img.select('cloud_mask').eq(1)\n",
    "\n",
    "    # Count total pixels \n",
    "    total_pixels = img.select('valid_pixel').reduceRegion(\n",
    "        reducer=ee.Reducer.sum(),\n",
    "        geometry=roi,\n",
    "        scale=10,\n",
    "        maxPixels=1e10\n",
    "    ).get('valid_pixel')\n",
    "\n",
    "    # Count cloudy pixels (value = 1)\n",
    "    cloudy_pixels = cloud_mask.reduceRegion(\n",
    "        reducer=ee.Reducer.sum(),\n",
    "        geometry=roi,\n",
    "        scale=10,\n",
    "        maxPixels=1e10\n",
    "    ).get('cloud_mask')  \n",
    "    \n",
    "    # Calculate cloud cover % - Avoid division by zero\n",
    "    cloud_cover = ee.Number(cloudy_pixels).divide(ee.Number(total_pixels)).multiply(100)\n",
    "        \n",
    "    # Attach as image property\n",
    "    return img.set({'cloud_cover': cloud_cover.round(), # round to nearest integer\n",
    "                    'cloudy_pixels': cloudy_pixels,\n",
    "                    'total_pixels': total_pixels}) \n",
    "\n",
    "# Convert image to feature\n",
    "def img_to_feature(img): \n",
    "    return ee.Feature(None, {'cloud_cover': img.get('cloud_cover'), \n",
    "                             'cloudy_pixels': img.get('cloudy_pixels'),\n",
    "                             'total_pixels': img.get('total_pixels'),\n",
    "                             'system:time_start' : img.get('system:time_start'),\n",
    "                             'date': img.get('date'),\n",
    "                             'start_time_range': img.get('start_time_range')})\n",
    "    \n",
    "# Export to Drive\n",
    "def export_table(fc, description):\n",
    "    task = ee.batch.Export.table.toDrive(\n",
    "        collection=fc,\n",
    "        description=description,\n",
    "        folder=drive_folder,\n",
    "        fileFormat='CSV'\n",
    "    )\n",
    "    task.start()\n",
    "    print(f\"Export started: {description}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Batch processing and export\n",
    "# -----------------------------\n",
    "current_start = start_date_total\n",
    "\n",
    "while current_start.millis().getInfo() < end_date_total.millis().getInfo():\n",
    "    # Define batch end date\n",
    "    current_end = current_start.advance(batch_months, 'month')\n",
    "    if current_end.millis().getInfo() > end_date_total.millis().getInfo():\n",
    "        current_end = end_date_total\n",
    "\n",
    "    print(f\"Processing batch: {current_start.format('YYYY-MM-dd').getInfo()} to {current_end.format('YYYY-MM-dd').getInfo()}\")\n",
    "\n",
    "    # ----------------- Small ROI -----------------\n",
    "    s2_cloud_small_roi = (ee.ImageCollection(\"COPERNICUS/S2_CLOUD_PROBABILITY\")\n",
    "        .filterDate(current_start, current_end)\n",
    "        .filterBounds(bergen_small_roi)\n",
    "        .map(add_cloud_mask)\n",
    "        .map(lambda img: has_valid_pixels(img, bergen_small_roi))\n",
    "        .filter(ee.Filter.gt('validPixelCount', 0))\n",
    "        .map(add_date)\n",
    "    )\n",
    "    \n",
    "    # Mosaic tiles into one image per day \n",
    "    s2_cloud_small_roi = daily_mosaic(s2_cloud_small_roi) \\\n",
    "                        .map(add_constant) \\\n",
    "                        .map(lambda img: add_cloud_cover(img, bergen_small_roi))\n",
    "    \n",
    "\n",
    "    fc_small = s2_cloud_small_roi.map(img_to_feature)\n",
    "    export_table(fc_small, f\"S2_cloud_cover_small_thresh_40_{current_start.format('YYYY-MM').getInfo()}\")\n",
    "\n",
    "    # ----------------- Large ROI -----------------\n",
    "    s2_cloud_large_roi = (ee.ImageCollection(\"COPERNICUS/S2_CLOUD_PROBABILITY\")\n",
    "        .filterDate(current_start, current_end)\n",
    "        .filterBounds(bergen_large_roi)\n",
    "        .map(add_cloud_mask)\n",
    "        .map(lambda img: has_valid_pixels(img, bergen_large_roi))\n",
    "        .filter(ee.Filter.gt('validPixelCount', 0))\n",
    "        .map(add_date)\n",
    "    )\n",
    "    \n",
    "    # Mosaic tiles into one image per day \n",
    "    s2_cloud_large_roi = daily_mosaic(s2_cloud_large_roi) \\\n",
    "                        .map(add_constant) \\\n",
    "                        .map(lambda img: add_cloud_cover(img, bergen_large_roi))\n",
    "\n",
    "    fc_large = s2_cloud_large_roi.map(img_to_feature)\n",
    "    export_table(fc_large, f\"S2_cloud_cover_large_thresh_40_{current_start.format('YYYY-MM').getInfo()}\")\n",
    "\n",
    "    # Move to next batch\n",
    "    current_start = current_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dee129d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <style>\n",
       "                .geemap-dark {\n",
       "                    --jp-widgets-color: white;\n",
       "                    --jp-widgets-label-color: white;\n",
       "                    --jp-ui-font-color1: white;\n",
       "                    --jp-layout-color2: #454545;\n",
       "                    background-color: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-dark .jupyter-button {\n",
       "                    --jp-layout-color3: #383838;\n",
       "                }\n",
       "\n",
       "                .geemap-colab {\n",
       "                    background-color: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "\n",
       "                .geemap-colab .jupyter-button {\n",
       "                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n",
       "                }\n",
       "            </style>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing date: 2015-07-29\n",
      "Exporting S2_cloud_mask_large_2015-07-29...\n",
      "Processing date: 2015-08-08\n",
      "Exporting S2_cloud_mask_large_2015-08-08...\n",
      "Processing date: 2015-08-21\n",
      "Exporting S2_cloud_mask_large_2015-08-21...\n",
      "Processing date: 2015-08-28\n",
      "Exporting S2_cloud_mask_large_2015-08-28...\n",
      "Processing date: 2015-08-31\n",
      "Exporting S2_cloud_mask_large_2015-08-31...\n",
      "Processing date: 2015-09-17\n",
      "Exporting S2_cloud_mask_large_2015-09-17...\n",
      "Processing date: 2015-10-20\n",
      "Exporting S2_cloud_mask_large_2015-10-20...\n",
      "Processing date: 2015-11-16\n",
      "Exporting S2_cloud_mask_large_2015-11-16...\n",
      "Processing date: 2016-02-04\n",
      "Exporting S2_cloud_mask_large_2016-02-04...\n",
      "Processing date: 2016-02-14\n",
      "Exporting S2_cloud_mask_large_2016-02-14...\n",
      "Processing date: 2016-03-05\n",
      "Exporting S2_cloud_mask_large_2016-03-05...\n",
      "Processing date: 2016-03-25\n",
      "Exporting S2_cloud_mask_large_2016-03-25...\n",
      "Processing date: 2016-04-27\n",
      "Exporting S2_cloud_mask_large_2016-04-27...\n",
      "Processing date: 2016-05-07\n",
      "Exporting S2_cloud_mask_large_2016-05-07...\n",
      "Processing date: 2016-05-14\n",
      "Exporting S2_cloud_mask_large_2016-05-14...\n",
      "Processing date: 2016-06-06\n",
      "Exporting S2_cloud_mask_large_2016-06-06...\n",
      "Processing date: 2016-06-13\n",
      "Exporting S2_cloud_mask_large_2016-06-13...\n",
      "Processing date: 2016-07-03\n",
      "Exporting S2_cloud_mask_large_2016-07-03...\n",
      "Processing date: 2016-07-13\n",
      "Exporting S2_cloud_mask_large_2016-07-13...\n",
      "Processing date: 2016-07-23\n",
      "Exporting S2_cloud_mask_large_2016-07-23...\n",
      "Processing date: 2016-07-26\n",
      "Exporting S2_cloud_mask_large_2016-07-26...\n",
      "Processing date: 2016-08-15\n",
      "Exporting S2_cloud_mask_large_2016-08-15...\n",
      "Processing date: 2016-08-22\n",
      "Exporting S2_cloud_mask_large_2016-08-22...\n",
      "Processing date: 2016-09-01\n",
      "Exporting S2_cloud_mask_large_2016-09-01...\n",
      "Processing date: 2016-09-11\n",
      "Exporting S2_cloud_mask_large_2016-09-11...\n",
      "Processing date: 2016-09-14\n",
      "Exporting S2_cloud_mask_large_2016-09-14...\n",
      "Processing date: 2016-09-21\n",
      "Exporting S2_cloud_mask_large_2016-09-21...\n",
      "Processing date: 2016-10-01\n",
      "Exporting S2_cloud_mask_large_2016-10-01...\n",
      "Processing date: 2016-10-04\n",
      "Exporting S2_cloud_mask_large_2016-10-04...\n",
      "Processing date: 2016-10-11\n",
      "Exporting S2_cloud_mask_large_2016-10-11...\n",
      "Processing date: 2016-10-14\n",
      "Exporting S2_cloud_mask_large_2016-10-14...\n",
      "Processing date: 2016-10-21\n",
      "Exporting S2_cloud_mask_large_2016-10-21...\n",
      "Processing date: 2016-10-24\n",
      "Exporting S2_cloud_mask_large_2016-10-24...\n",
      "Processing date: 2016-11-03\n",
      "Exporting S2_cloud_mask_large_2016-11-03...\n",
      "Processing date: 2016-11-10\n",
      "Exporting S2_cloud_mask_large_2016-11-10...\n",
      "Processing date: 2016-11-13\n",
      "Exporting S2_cloud_mask_large_2016-11-13...\n",
      "Processing date: 2016-11-20\n",
      "Exporting S2_cloud_mask_large_2016-11-20...\n",
      "Processing date: 2016-11-23\n",
      "Exporting S2_cloud_mask_large_2016-11-23...\n",
      "Processing date: 2017-01-29\n",
      "Exporting S2_cloud_mask_large_2017-01-29...\n",
      "Processing date: 2017-02-08\n",
      "Exporting S2_cloud_mask_large_2017-02-08...\n",
      "Processing date: 2017-02-11\n",
      "Exporting S2_cloud_mask_large_2017-02-11...\n",
      "Processing date: 2017-02-21\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Pipeline for exporting large roi cloud mask images for shadow computation \n",
    "# =============================================================================\n",
    "\n",
    "# -----------------------------\n",
    "# Parameters\n",
    "# -----------------------------\n",
    "CLD_PRB_THRESH = 40\n",
    "mixed_thresh = 1\n",
    "overcast_thresh = 99\n",
    "drive_folder = \"S2_cloud_mask_daily_large_ROI_thresh_40\"\n",
    "cloud_cover_filepath = \"../../data/processed/s2_cloud_cover_table_small_and_large_with_stations_data.csv\"\n",
    "\n",
    "# Read cloud cover table and extract observations with mixed sky type \n",
    "cloud_cover_table = pd.read_csv(cloud_cover_filepath)\n",
    "cloud_cover_mixed = cloud_cover_table[\n",
    "    (cloud_cover_table[\"cloud_cover_large\"] > mixed_thresh) &\n",
    "    (cloud_cover_table[\"cloud_cover_large\"] < overcast_thresh)\n",
    "]\n",
    "\n",
    "# Unique dates for mixed sky days\n",
    "unique_dates = cloud_cover_mixed['date'].unique()\n",
    "\n",
    "# -----------------------------\n",
    "# Helper functions\n",
    "# -----------------------------\n",
    "def export_image(image, description):\n",
    "    task = ee.batch.Export.image.toDrive(\n",
    "        image=image,\n",
    "        description=description,\n",
    "        folder=drive_folder,\n",
    "        fileNamePrefix=description,\n",
    "        region=bergen_large_roi,\n",
    "        scale=10,\n",
    "        maxPixels=1e13\n",
    "    )\n",
    "    task.start()\n",
    "\n",
    "# -----------------------------\n",
    "# Export loop for unique dates\n",
    "# -----------------------------\n",
    "for date_str in unique_dates:\n",
    "    print(f\"Processing date: {date_str}\")\n",
    "\n",
    "    start_date = ee.Date(date_str)\n",
    "    end_date = start_date.advance(1, 'day')\n",
    "\n",
    "    # Load image collection for this batch\n",
    "    s2_cloud_ic = (ee.ImageCollection(\"COPERNICUS/S2_CLOUD_PROBABILITY\")\n",
    "                   .filterDate(start_date, end_date) # treats end-date exclusively\n",
    "                   .filterBounds(bergen_large_roi)\n",
    "                   .map(add_cloud_mask)\n",
    "                )\n",
    "\n",
    "    # Check if there is any valid image\n",
    "    n_images = s2_cloud_ic.size().getInfo()\n",
    "    if n_images == 0:\n",
    "        print(f\"⚠️ No valid image for {date_str}, skipping...\")\n",
    "        continue\n",
    "\n",
    "    # Create daily mosaic\n",
    "    daily_image = s2_cloud_ic.mosaic().set('date', date_str)\n",
    "\n",
    "    # Export\n",
    "    description = f\"S2_cloud_mask_large_{date_str}\"\n",
    "    export_image(daily_image, description)\n",
    "    print(f\"Exporting {description}...\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geemap-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
